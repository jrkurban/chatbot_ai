import streamlit as st
import google.generativeai as genai
import time

# --- SAYFA AYARLARI ---
st.set_page_config(
    page_title="Batuhan AI | Dijital Asistan",
    page_icon="ğŸ‘¨â€ğŸ’»",
    layout="centered"
)

# --- API AYARLARI ---
# GÃ¼venlik Notu: API anahtarÄ±nÄ± kodun iÃ§ine direkt yazmak yerine
# Streamlit Secrets kullanacaÄŸÄ±z. AÅŸaÄŸÄ±da detayÄ±nÄ± anlattÄ±m.
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except Exception as e:
    st.error("API Key bulunamadÄ±. LÃ¼tfen ..streamlit/secrets.toml dosyasÄ±nÄ± kontrol et.")
    st.stop()

# --- SENÄ°N VERÄ°TABANIN (BEYÄ°N) ---
# BurayÄ± kendi gerÃ§ek bilgilerinle doldurmalÄ±sÄ±n.
# Ne kadar detay verirsen, asistan o kadar iyi konuÅŸur.
MY_DATA = """
Ä°sim: Batuhan
Rol: Senior Backend Developer (5 YÄ±l Deneyim)
Lokasyon: Ä°stanbul / Uzaktan Ã§alÄ±ÅŸabilir
Teknolojiler: Python (Django, FastAPI), Go, Docker, Kubernetes, AWS, PostgreSQL.
Ã–ne Ã‡Ä±kan Proje 1: E-ticaret AltyapÄ±sÄ±. Mikroservis mimarisiyle saniyede 10k istek karÅŸÄ±layan sistem kurdu. (github.com/batuhan/ecommerce)
Ã–ne Ã‡Ä±kan Proje 2: AI Chatbot Entegrasyonu. RAG mimarisi kullanarak ÅŸirket iÃ§i dokÃ¼man asistanÄ± yazdÄ±.
Hobiler: No Man's Sky oynamak, yeni teknolojileri kurcalamak.
KiÅŸilik: Profesyonel, Ã§Ã¶zÃ¼m odaklÄ± ama samimi. KÄ±sa ve net cevaplar vermeyi sever.
Ã–zel Talimat: EÄŸer kullanÄ±cÄ± "gÃ¶rÃ¼ÅŸmek istiyorum", "mÃ¼lakat", "iÅŸe alÄ±m" gibi ÅŸeyler derse, onlara Batuhan'a hemen bildirim gÃ¶nderdiÄŸini sÃ¶yle ve mail adresini (batuhan@mail.com) ver.
"""

# --- MODEL AYARLARI ---
# System Instruction: Modele kim olduÄŸunu Ã¶ÄŸretiyoruz.
model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    system_instruction=f"Sen Batuhan'Ä±n yapay zeka asistanÄ±sÄ±n. AmacÄ±n iÅŸe alÄ±m uzmanlarÄ±na Batuhan'Ä± tanÄ±tmak. AÅŸaÄŸÄ±daki bilgilere dayanarak cevap ver. BilmediÄŸin bir ÅŸey sorulursa dÃ¼rÃ¼stÃ§e 'Bu konuda bilgim yok ama Batuhan'a sorabilirim' de. Asla kendi baÅŸÄ±na bilgi uydurma. \n\nVeri: {MY_DATA}"
)

# --- ARAYÃœZ TASARIMI ---
st.title("Merhaba, ben Batuhan'Ä±n AI AsistanÄ± ğŸ‘‹")
st.markdown("""
> *"Projelerimi incelemek iÃ§in Github linklerine tÄ±klayabilir veya bana doÄŸrudan soru sorabilirsiniz."*
""")

# Sohbet GeÃ§miÅŸini BaÅŸlat
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Ä°lk karÅŸÄ±lama mesajÄ±
    st.session_state.messages.append({"role": "model", "parts": [
        "Selam! Batuhan ÅŸu an kod yazÄ±yor olabilir. Onun hakkÄ±nda ne bilmek istersin? Projeleri, tecrÃ¼besi veya kullandÄ±ÄŸÄ± teknolojiler?"]})

# MesajlarÄ± Ekrana Bas
for message in st.session_state.messages:
    role = "user" if message["role"] == "user" else "assistant"
    with st.chat_message(role):
        st.markdown(message["parts"][0])

# --- KULLANICI GÄ°RDÄ°SÄ° VE CEVAP ---
if prompt := st.chat_input("Sorunuzu buraya yazÄ±n..."):
    # KullanÄ±cÄ± mesajÄ±nÄ± ekle
    st.session_state.messages.append({"role": "user", "parts": [prompt]})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Asistan cevabÄ±nÄ± oluÅŸtur
    with st.chat_message("assistant"):
        message_placeholder = st.empty()

        try:
            # Gemini'ye sohbet geÃ§miÅŸini gÃ¶ndererek baÄŸlamÄ± koruyoruz
            chat = model.start_chat(history=st.session_state.messages[:-1])
            response = chat.send_message(prompt, stream=True)

            full_response = ""
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    # Daktilo efekti iÃ§in ufak gecikme (Vibe iÃ§in Ã¶nemli)
                    message_placeholder.markdown(full_response + "â–Œ")
                    time.sleep(0.01)

            message_placeholder.markdown(full_response)

            # CevabÄ± geÃ§miÅŸe kaydet
            st.session_state.messages.append({"role": "model", "parts": [full_response]})

        except Exception as e:
            st.error(f"Bir hata oluÅŸtu: {str(e)}")